# -*- coding: utf-8 -*-
"""Dicoding Machine Learning Terapan Submission

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-aCfpJ_ekw-OKMzl5DXCfh51vaWBPbpV

# Proyek Machine Learning: Date  Fruit Classification

- **Nama:** Umar Sani
- **Email:** umarsani@student.uns.ac.id
- **ID Dicoding:** umarsani16

## Import Libraries
"""

import zipfile
import os, shutil
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""## Load Data"""

# Unduh dataset dari Kaggle

! kaggle datasets download -d muratkokludataset/date-fruit-datasets

# Ekstrak dataset

def extract(source, destination):
    zip = zipfile.ZipFile(source, "r")
    zip.extractall(destination)
    zip.close()
    print("[SUCCESS] {} berhasil diekstrak ke '{}'".format(os.path.basename(source), destination))

source = "/content/date-fruit-datasets.zip"
destination = "/content/date-fruit-datasets"

extract(source, destination)

# Muat dataset yang berbentuk .xlsx

df = pd.read_excel('/content/date-fruit-datasets/Date_Fruit_Datasets/Date_Fruit_Datasets.xlsx')

"""## Data Analysis

Pertama, mari kita lihat bagaimana struktur dataset tersebut dengan menampilkan 10 baris teratas.
"""

df.head(10)

"""Berikutnya, kita cek informasi setiap setiap fitur dan apakah ada nilai null di dalamnya."""

df.info()

"""Berdasarkan data diatas, semua fitur merupakan data numerik, kecuali untuk kolom Class yang merupakan kolom target.

Selain itu, nilai null tidak ditemukan pada dataset tersebut.

Berikutnya, mari kita lihat statistik dari setiap fitur dataset.
"""

df.describe()

"""Berdasarkan informasi diatas, dapat dilihat bahwa setiap fitur memiliki rentang nilai atau skala yang berbeda. Pada tahap preprocessing skala nilai setiap fitur akan kita normalisasikan agar model machine learning dapat memproses data lebih efisien.

Selanjutnya, mari kita lihat perbandingan jumlah data untuk setiap kelas.
"""

fig = plt.figure(figsize=(16, 6))
ax = fig.add_subplot()

sns.countplot(x='Class', data=df, ax=ax, order=df['Class'].value_counts().index, color='#f4811d')

ax.set_title('Perbandingan Kelas', pad=24)
ax.set_xlabel('Jumlah')
ax.set_ylabel('Kelas')

ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

for p in ax.patches:
    x = p.get_bbox().get_points()[:, 0]
    y = p.get_bbox().get_points()[1, 1]
    ax.annotate('{}\n{:.1f}%'.format(int(y), 100. * y / len(df)), (x.mean(), y), ha='center', va='bottom')

"""Lakukan scatterplot dan heatmap untuk melihat korelasi setiap fitur dengan fitur yang lain."""

pd.plotting.scatter_matrix(df, figsize=(36, 36))

df_features = df.drop('Class', axis=1)

plt.figure(figsize=(20,20))

mask = np.triu(np.ones_like(df_features.corr(), dtype=bool))

sns.heatmap(df_features.corr(), annot=True, cmap='coolwarm')

plt.title("Correlation Matrix", size=22, fontweight="bold")
plt.tight_layout()

"""Berdasarkan scatterplot dan correlation matrix diatas, setiap fitur cenderung memiliki korelasi dengan fitur-fitur yang lain. Walaupun ada fitur yang tidak berkolerasi dengan beberapa fitur lainnya, tetap ada pasangan fitur lain yang berkolerasi. Oleh karena itu, kita tidak akan mengurangi fitur.

Selanjutnya, mari kita lihat distribusi jumlah baris untuk setiap fitur dataset dengan histogram.
"""

# histogram

df.hist(figsize=(20, 20), bins=50)

"""Berdasarkan gambar diatas, setiap fitur dataset memiliki skewness atau kesimetrisan yang beragam.

Berikutnya, kita lihat distribusi data untuk setiap fitur dan setiap kelas dengan KDE plot. KDE plot memungkinkan perbandingan distribusi antar kelas dalam dataset dengan visualisasi yang lebih jelas.
"""

# KDE plot

features = [col for col in df.columns if col != 'Class']

n_rows = len(features) // 2 + len(features) % 2
n_cols =  2

fig, ax = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))

ax = ax.flatten()

for i, column in enumerate(features):
    sns.kdeplot(data=df, ax=ax[i], x=column, hue="Class", fill=True, legend=True)

plt.tight_layout()

plt.show()

"""KDE plot sebenarnya tidak jauh berbeda dengan histogram, namun dengan grafik yang lebih halus dan perbandingan antar kelas yang lebih jelas.

## Data Preprocessing

Kita telah melakukan eksplorasi dataset, sekarang kita akan melakukan preprocessing agar dataset dapat digunakan oleh model machine learning.

Pertama, kita lakukan pembagian dataset menjadi data training dan testing, dengan perbandingan 80:20.
"""

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler

X = df.drop("Class", axis = 1)
y = df["Class"]

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=123)

"""Kedua, kita lakukan normalisasi dengan StandardScaler agar semua fitur berada pada skala yang sama. Selain itu, normalisasi akan mempercepat dan mengefisiensi kinerja model machine learning."""

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train = pd.DataFrame(X_train_scaled)
X_test = pd.DataFrame(X_test_scaled)

"""## Model Building

Pada tahap ini, beberapa model machine learning digunakan untuk mengklasifikasi varietas buah kurma. Model yang digunakan yaitu Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest, Logistic Regression, Naive Bayes, Multi-Layer Perceptron (MLP), dan XGBoost.

Setiap model akan dilakukan proses training dan testing. Hasil akurasi dari setiap model akan disimpan untuk dilakukan perbandingan model terbaik.
"""

model_scores = {}

"""### SVM

SVM adalah model machine learning yang  bekerja dengan mencari hyperplane terbaik yang memisahkan data ke dalam setiap kelas yang berbeda.

Model yang digunakan SVC (Support Vector Classifier), jenis SVM yang khusus digunakan untuk klasifikasi.Kernel yang digunakan yaitu linear dengan C=1. Parameter dipilih yang terbaik berdasarkan beberapa kali running.
"""

from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score

svm_classifier = SVC(probability=True, C=1, kernel='linear', random_state=123)

# Proses training
svm_classifier.fit(X_train, y_train)

# Proses prediksi
y_pred_svm = svm_classifier.predict(X_test)

# Evaluasi model
model_scores['SVM'] = accuracy_score(y_test, y_pred_svm) * 100

print("SVM Classification Report:\n", classification_report(y_test, y_pred_svm))
print("SVM Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_svm) * 100))

"""### K-Nearest Neighbors (KNN)

K-Nearest Neighbors (KNN) adalah algoritma klasifikasi yang bekerja dengan mencari sejumlah (k) tetangga terdekat dari data baru berdasarkan jarak tertentu.
"""

from sklearn.neighbors import KNeighborsClassifier

knn_classifier = KNeighborsClassifier(n_neighbors=3)

# Melatih model
knn_classifier.fit(X_train, y_train)

# Menguji model
y_pred_knn = knn_classifier.predict(X_test)

# Evaluasi model
model_scores['KNN'] = accuracy_score(y_test, y_pred_knn) * 100

print("KNN Classification Report:\n", classification_report(y_test, y_pred_knn))
print("KNN Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_knn) * 100))

"""### Random Forest Classifier

Random Forest adalah model machine learning berbasis ensemble yang menggabungkan hasil dari banyak pohon keputusan (decision tree).

Parameter n_estimators dan max_depth dipilih berdasarkan beberapa kali hasil running.
"""

from sklearn.ensemble import RandomForestClassifier

rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=123)

# Melatih model
rf_classifier.fit(X_train, y_train)

# Menguji model
y_pred_rf = rf_classifier.predict(X_test)

# Evaluasi model
model_scores['Random Forest'] = accuracy_score(y_test, y_pred_rf) * 100

print("Random Forest Classification Report:\n", classification_report(y_test, y_pred_rf))
print("Random Forest Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_rf) * 100))

"""### Logistic Regression

Logistic Regression adalah metode statistik yang digunakan untuk memprediksi probabilitas kejadian berdasarkan satu atau lebih variabel independen.
"""

from sklearn.linear_model import LogisticRegression

lr_classifier = LogisticRegression(max_iter=1000, random_state=123)

# Melatih model
lr_classifier.fit(X_train, y_train)

# Menguji model
y_pred_lr = lr_classifier.predict(X_test)

# Evaluasi model
model_scores['Logistic Regression'] = accuracy_score(y_test, y_pred_lr) * 100

print("Logistic Regression Classification Report:\n", classification_report(y_test, y_pred_lr))
print("Logistic Regression Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_lr) * 100))

"""### Naive Bayes Classifier

Naive Bayes adalah algoritma klasifikasi yang didasarkan pada Teorema Bayes dengan asumsi semua fitur independen satu sama lain.
"""

from sklearn.naive_bayes import GaussianNB

nb_classifier = GaussianNB()

# Melatih model
nb_classifier.fit(X_train, y_train)

# Menguji model
y_pred_nb = nb_classifier.predict(X_test)

# Evaluasi model
model_scores['Naive Bayes'] = accuracy_score(y_test, y_pred_nb) * 100

print("Naive Bayes Classification Report:\n", classification_report(y_test, y_pred_nb))
print("Naive Bayes Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_nb) * 100))

"""### Multi-Layer Perceptron (MLP)

Multi-Layer Perceptron (MLP) adalah jenis jaringan saraf tiruan yang terdiri dari beberapa lapisan neuron. Model ini bekerja dengan mengirimkan data melalui beberapa lapisan tersembunyi, yang memungkinkan jaringan untuk belajar representasi yang lebih kompleks dari data.
"""

from sklearn.neural_network import MLPClassifier

mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,
                     solver='adam', verbose=10,  random_state=123)

# Melatih model
mlp_classifier.fit(X_train, y_train)

# Menguji model
y_pred_mlp = mlp_classifier.predict(X_test)

# Evaluasi model
model_scores['MLP'] = accuracy_score(y_test, y_pred_mlp) * 100

print('')
print("MLP Classification Report:\n", classification_report(y_test, y_pred_mlp))
print("MLP Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_mlp) * 100))

"""### XGBoost

XGBoost (Extreme Gradient Boosting) adalah sebuah algoritma machine learning yang berbasis pada teknik boosting, di mana model dibangun secara bertahap dengan menambahkan model baru yang memperbaiki kesalahan dari model sebelumnya.
"""

import xgboost as xgb

xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=7, random_state=123) # adjust parameters as needed

# Melatih model
xgb_classifier.fit(X_train, y_train)

# Menguji model
y_pred_xgb = xgb_classifier.predict(X_test)

# Evaluasi model
model_scores['XGBoost'] = accuracy_score(y_test, y_pred_xgb) * 100

print("XGBoost Classification Report:\n", classification_report(y_test, y_pred_xgb))
print("XGBoost Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_xgb) * 100))

"""## Evaluation

Pada tahap evaluasi, metrik yang digunakan adalah akurasi. Akurasi mengukur persentase jumlah prediksi yang benar dari total prediksi. Di bawah ini merupakan dataframe akurasi hasil testing dari model-model yang digunakan.
"""

df_model_scores = pd.DataFrame.from_dict(model_scores, orient='index', columns=['Accuracy'])
df_model_scores

"""Berikut merupakan visualisasi perbandingan akurasi dari semua model."""

plt.figure(figsize=(10, 6))
ax = sns.barplot(x=df_model_scores.index, y='Accuracy', data=df_model_scores, color='#f4811d')

ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

plt.title('Perbandingan Akurasi Setiap Model')
plt.xlabel('Jenis Model')
plt.ylabel('Akurasi (%)')
plt.xticks(rotation=45, ha='right')
plt.ylim(85, 95)  # Limit y-axis from 85 to 95

ax.axhline(y = max(df_model_scores['Accuracy'].tolist()) , linewidth = 1, color = "red", linestyle="dashed")

for p in ax.patches:
    x = p.get_bbox().get_points()[:, 0]
    y = p.get_bbox().get_points()[1, 1]
    ax.annotate('{:.2f}%'.format(y), (x.mean(), y), ha='center', va='bottom')

plt.tight_layout()
plt.show()

"""Berdasarkan grafik di atas, semua model mendapatkan hasil yang baik dengan akurasi terendah yaitu Naive Bayes dengan akurasi 88.89% dan akurasi terbaik yaitu Logistic Regression dengan akurasi 92.78%.

## Summary

Berdasarkan percobaan-percobaan yang telah dilakukan, model machine learning berhasil mendapatkan hasil yang baik dalam mengklasifikasikan varietas kurma. Model machine learning yang mendapatkan akurasi  terbaik adalah Logistic Regression dengan akurasi 92.78%.
"""