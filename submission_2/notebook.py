# -*- coding: utf-8 -*-
"""dicoding-advanced-machine-learning-2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/dicoding-advanced-machine-learning-2-3f59943b-a828-417a-a4f0-2f020a6b7a91.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request%26X-Goog-Date%3D20241101T154333Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D840ca123736604ac798aa00f37dc1fb2b26156d208fa7e372564d01d05522ab874e2a94d1e0af268befeca30d09ac621032cd0869ceed16e1575375c2fd1388155452f10f556783ada9a90a855a47901ed04014c46fc7a6aab89945c40b9ac0d4b1eb300c2c86fa980f124e4415f8238424f8495b88a703fefea78d08e0424223841ecce33f12d6b925ed1d3a15d226e75982fa95bee4c2b36782e456ee17c5a592601f272883ed9f46ae51e63f98326b6ba08fcda5c942675cdf294652276d5165970aec8b421c6dde3669edd184584a699bf0438afea7f1d686d575fa5e3164d6416f5640593f31cb396fb35caf4c3b3afd77fb1cf41838550b8f56b8e05c2

# Proyek Machine Learning: Recommender System

- **Nama:** Umar Sani
- **Email:** umarsani@student.uns.ac.id
- **ID Dicoding:** umarsani16

## Import Libraries
"""

import string
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
from ast import literal_eval
from datetime import datetime
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import zipfile
import os, shutil

# set pandas agar tidak memotong kolom
pd.set_option("display.max_columns", 0)

"""## Load Data"""

# Notebook ini dijalankan pada lingkungan Kaggle
# Apabila memakai selain Kaggle jalankan dua sel berikut

# ! kaggle datasets download -d rounakbanik/the-movies-dataset

# # Ekstrak dataset
# def extract(source, destination):
#     zip = zipfile.ZipFile(source, "r")
#     zip.extractall(destination)
#     zip.close()
#     print("[SUCCESS] {} berhasil diekstrak ke '{}'".format(os.path.basename(source), destination))

# source = "/content/the-movies-dataset.zip"
# destination = "/content/the-movies-dataset"

# extract(source, destination)

movies = pd.read_csv('../input/the-movies-dataset/movies_metadata.csv')
keywords = pd.read_csv('../input/the-movies-dataset/keywords.csv')
credits = pd.read_csv('../input/the-movies-dataset/credits.csv')

"""## Data Cleaning and Preprocessing

Pertama, mari pahami dataset dengan melihat struktur masing-masing file yang telah di-import. File-file ini nanti akan digabungkan menjadi satu dataframe

### Dataframe Movies

Tampilkan 5 baris data teratas, serta informasi jumlah dan tipe dataset.
"""

movies.head()

movies.info()

"""Dari informasi diatas, dapat dilihat ada beberapa kolom yang tipe datanya object. Kolom-kolom tersebut akan diubah tipe datanya agar mudah untuk diolah."""

movies['belongs_to_collection'][0]

movies['genres'][0]

movies['production_companies'][0]

movies['production_countries'][0]

movies['spoken_languages'][0]

"""Drop kolom-kolom metadata yang kurang berhubungan dengan informasi movie itu sendiri. Selain itu, terdapat beberapa baris yang bertipe data salah, karena akan membuat error pada saat pengolahan data."""

movies = movies.drop(['belongs_to_collection', 'homepage', 'imdb_id', 'poster_path', 'status', 'title', 'video'], axis=1).drop([19730, 29503, 35587])
movies.head()

"""Sekarang, ubah kolom-kolom yang bertipe data object menjadi list."""

def object_to_list(x):
    if isinstance(x, str):
        names = [i['name'] for i in literal_eval(x)]
        # Jika terdapat lebih dari tiga elemen, ambil tiga pertama saja.
        if len(names) > 3:
            names = names[:3]
        return names
    else:
        return []

for column_name in ['production_companies', 'production_countries', 'spoken_languages', 'genres']:
    movies[column_name] = movies[column_name].apply(object_to_list)

movies.head()

"""Sekarang, dataframe movie telah lebih rapi.

### Dataframe Keywords

Berikutnya, tampilkan 5 baris data teratas dari dataframe Keywords, serta informasi jumlah dan tipe dataset.
"""

keywords.head()

keywords.info()

keywords['keywords'][0]

"""Sama seperti dataframe Movies, lakukan konversi tipe data object menjadi list pada kolom yang belum sesuai."""

# data prep
keywords['keywords'] = keywords['keywords'].apply(object_to_list)
keywords.head()

"""### Dataframe Credits

Berikutnya, tampilkan 5 baris data teratas dari dataframe Credits, serta informasi jumlah dan tipe dataset.
"""

credits.head()

credits.info()

credits['cast'][0]

credits['crew'][0]

"""Sama seperti dataframe sebelumya, lakukan konversi tipe data object menjadi list pada kolom yang belum sesuai.

Selain itu, kolom crew hanya akan diambil nama director-nya saja dan men-drop kolom crew itu sendiri.
"""

def get_director(x):
  try:
    crew_list = literal_eval(x)
    director = [member['name'] for member in crew_list if member['job'] == 'Director']
    return director[0]
  except:
    return ''

credits['cast'] = credits['cast'].apply(object_to_list)
credits['director'] = credits['crew'].apply(get_director)

credits = credits.drop(['crew'], axis=1)

credits.head()

credits['cast'][0]

"""### Dataframe Gabungkan

Setelah setiap dataframe telah rapi, gabungkan semua dataframe menjadi satu.
"""

movies['id'] = movies['id'].astype('int64')

df = movies.merge(keywords, on='id')
df = df.merge(credits, on='id')

df.head()

"""Cek informasi setiap kolom dataset dan apakah ada nilai null."""

df.info()

df.isnull().sum()

"""Terdapat cukup banyak kolom yang memiliki nilai null.

Kolom dengan tipe string akan diisi dengan string kosong. Sedangkan kolom dengan tipe numerik akan diisi dengan nilai mean.
"""

fill_string = ['original_language', 'overview', 'tagline', 'release_date']

for column in fill_string:
  df[column] = df[column].fillna('')

df['popularity'] = df['popularity'].astype('float64')

fill_mean = ['popularity', 'revenue', 'runtime', 'vote_average', 'vote_count']

for column in fill_mean:
  df[column] = df[column].fillna(df[column].mean())

df.isnull().sum()

"""Sekarang, dataset telah bersih dari nilai null.

Pada percobaan ini, sistem rekomendasi akan menggunakan pendekatan Content-based Filtering. Metadata items yang digunakan adalah genres, keywords, cast, dan director yang terkait dengan masing-masing film.
"""

df[['original_title', 'genres', 'keywords', 'cast', 'director']].head()

"""Pertama, bersihkan data dengan mengubah semua string menjadi lower case dan menghapus spasi di setiap frasanya."""

def data_cleaning(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

content_features = ['genres', 'keywords', 'cast', 'director', ]

for feature in content_features:
    df[feature] = df[feature].apply(data_cleaning)

df[['original_title', 'genres', 'keywords', 'cast', 'director']].head()

"""Setelah itu, buat kolom baru dengan nama content_filter, yang merupakan string gabungan genres, keywords, cast, dan director."""

def create_content_filter(x):
    return ' '.join(x['genres']) + ' ' + ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director']

df['content_filter'] = df.apply(create_content_filter, axis=1)
df['content_filter'].head()

df['content_filter'][0]

"""Sekarang, dataset telah bersih dan siap untuk dilakukan visualisasi dan modeling.

## Data Visualization

### Genre Movie Terbanyak

Dari visualisasi dibawah, dapat dilihat bahwa genre film dengan jumlah terbanyak adalah drama, diikuti oleh komedi dan aksi.
"""

genres_list = []
for i in df['genres']:
    genres_list.extend(i)

fig = plt.figure(figsize=(16, 6))

df_top_10 = pd.DataFrame(Counter(genres_list).most_common(10), columns=['genre', 'total'])

ax = sns.barplot(data=df_top_10, x='genre', y='total', color='#fb4137')

ax.set_title('10 Genre dengan Film Terbanyak', pad=24)
ax.set_xlabel('Genre')
ax.set_ylabel('Jumlah')

sns.despine()

for p in ax.patches:
    x = p.get_bbox().get_points()[:, 0]
    y = p.get_bbox().get_points()[1, 1]
    ax.annotate('{}'.format(int(y)), (x.mean(), y), ha='center', va='bottom')

"""### Distribusi Film Berdasarkan Tanggal Rilis

Berdasarkan visualisasi di bawah, dapat dilihat bahwa produksi film meningkat pada dekade 2000 hingga sekarang.
"""

df['release_date'] = pd.to_datetime(df['release_date'])

fig = plt.figure(figsize=(16, 6))

sns.displot(data=df, x='release_date', kind='hist', kde=True, color='#18d7ca', facecolor='#fb4137', edgecolor='#fff', aspect=3)

plt.title('Distribusi Film Berdasarkan Tanggal Rilis')

"""### Word Cloud

Berdasarkan word cloud dari plot film, dapat dilihat bahwa kata yang sering muncul adalah "one", "life", "love", "find", "family", dan "live".
"""

plt.figure(figsize=(20,20))

plt.title('Kata dengan Kemunculan Terbanyak')

wc = WordCloud(max_words=100, min_font_size=10, height=600, width=1200, background_color="white", colormap='turbo').generate(' '.join(df['overview']))

plt.imshow(wc)

"""## Modeling and Results

Sistem rekomendasi pada percobaan ini akan menggunakan Count Vectorizer. Count Vectorizer akan menghitung frekuensi kemunculan kata dalam dokumen dan menghasilkan vektor yang mewakili jumlah kemunculan kata-kata tersebut.

Di bawah ini merupakan visualisasi dari Count Vectorizer (Shah *et al.*, 2020).

![image.png](attachment:944b9885-c6c6-4068-a3d8-9f1c00a9d097.png)

Lakukan vektorisasi terhadap content_filter menggunakan fungsi fit_transform.
"""

cv = CountVectorizer()
vector_matrix = cv.fit_transform(df['content_filter'])

"""Dari matriks vektor hasil Count Vectorizer, jarak similaritas diantara setiap vektor akan dihitung dengan Cosine Similarity.

Cosine similarity mengukur sudut kosinus antara dua vektor (Neuralis, 2023). Nilai cosine similarity berkisar antara -1 hingga 1, di mana:

- 1 menunjukkan bahwa dua vektor memiliki arah yang sama (sangat mirip).

- 0 menunjukkan bahwa dua vektor ortogonal (tidak ada kesamaan).

- -1 menunjukkan bahwa dua vektor memiliki arah yang berlawanan (sangat tidak mirip).

Di bawah ini merupakan visualisasi dari Cosine Similarity (Neuralis, 2023).

![image.png](attachment:d03417ea-8845-4ea8-9bcf-701b4d9ab1c2.png)

Hitung cosine similarity antara matriks vektor dengan matriks vektor itu sendiri.
"""

cos_similarity = cosine_similarity(vector_matrix, vector_matrix)

"""(catatan: jika menggunakan Google Colab Free, runtime akan mengalami out of memory)

Setelah matriks similaritas didapatkan, buat fungsi find_recommendations untuk mendapatkan rekomendasi film. Fungsi tersebut akan menghitung jarak similaritas antara film yang diinputkan dengan film-film lainnya. Setelah itu, film-film dengan skor similaritas yang sama akan didapatkan dan diurutkan berdasarkan skor tertinggi. Kemudian, 10 besar film dengan skor similaritas tertinggi akan dikembalikan.
"""

# reset index dataframe agar urut kembali
df = df.reset_index()

def find_recommendations(movies, cos_similarity):
    idx = movies['index'].values[0]
    sim_scores = list(enumerate(cos_similarity[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    movies_idx = [i[0] for i in sim_scores]
    movies_result = df[['original_title', 'overview', 'genres', 'cast', 'vote_average']].iloc[movies_idx]
    return movies_result.reset_index()

"""Sebagai contoh, cari rekomendasi film yang mirip dengan film "Toy Story"."""

movie_to_find = df[df['original_title'] == 'Toy Story']

results = find_recommendations(movie_to_find, cos_similarity)

results

"""Dapat dilihat bahwa sistem rekomendasi berhasil membuat rekomendasi film yang mirip dengan "Toy Story".

## Evaluation

Untuk mengukur seberapa baik sistem rekomendasi bekerja. Metrik yang dapat digunakan adalah precision. Metrik precision akan menghitung proporsi item yang direkomendasikan yang relevan dengan pengguna.

Metrik precision pada sistem rekomendasi ditunjukkan oleh formula berikut.

$Precision = \frac{\text{Jumlah item relevan yang direkomendasikan}}{\text{Jumlah total item yang direkomendasikan}} $

Jumlah item relevan adalah jumlah film dengan genre yang mirip.

Jumlah total item adalah jumlah film yang direkomendasikan oleh sistem.

Sebagai contoh, buat rekomendasi film berdasarkan film "Star Wars"
"""

movie_to_find = df[df['original_title'] == 'Star Wars']

results = find_recommendations(movie_to_find, cos_similarity)

results

"""10 rekomendasi film telah didapatkan.

Untuk mendapatkan jumlah film yang relevan, hitung similaritas berdasarkan kolom genre antara movie_to_find dengan film-film hasil rekomendasi.
"""

movie_to_find['genres'].tolist()[0]

results['genres'].tolist()

"""Similaritas genre antara satu film dengan film yang lain akan dihitung dengan menggunakan jaccard similarity. Jackard similarity adalah metrik yang digunakan untuk mengukur tingkat kesamaan antara dua himpunan.

Jackard similarity ditunjukkan oleh formula berikut.

$ J(A, B) = \frac{|A \cap B|}{|A \cup B|} $

$ dengan: $

$ A = Set1 $

$ B = Set2 $

Buat fungsi untuk menghitung jaccard similarity
"""

def jaccard_similarity(list1, list2):
    set1 = set(list1)
    set2 = set(list2)
    intersection = set1.intersection(set2)
    union = set1.union(set2)
    return len(intersection) / len(union)

"""Berikutnya, lakukan perhitungan jaccard similarity dari film yang ingin dicari dengan film-film hasil rekomendasi."""

list_1 = movie_to_find['genres'].tolist()[0]
list_2 = results['genres'].tolist()

similarities = []

for result in list_2:
  jack_similarity = jaccard_similarity(list_1, result)
  similarities.append(jack_similarity)

jackard_result = pd.DataFrame({'Movie': range(1, len(results) + 1), 'Jaccard Similarity': similarities})

jackard_result

"""Misalkan ditentukan film yang relevan adalah film dengan similaritas diatas 0.8, sehingga dari tabel similaritas diatas didapatan ada 9 film yang relevan.

Untuk menghitung precision, jumlah dari film yang relevan akan dibagi dengan jumlah film rekomendasi.
"""

relevan_movie = jackard_result[jackard_result['Jaccard Similarity'] >= 0.8]

precision = len(relevan_movie)/len(results)

print(f"Precision: {precision*100}%")

"""Berdasarkan perhitungan diatas, precision sebesar 90%. Hasil tersebut sudah cukup bagus untuk sebuah sistem rekomendasi.

## Summary

Berdasarkan percobaan-percobaan yang telah dilakukan, model sistem rekomendasi yang dibuat berhasil mendapatkan rekomendasi film-film yang terkait dengan film yang diinputkan. Rekomendasi didapatkan berdasarkan kemiripan genre, kata kunci, pemeran, dan sutradara. Model sistem rekomendasi berhasil mendapatkan presisi sebesar 90%.

## Referensi

Neuralis. (2023, February 25). How Cosine similarity can improve your machine learning Models - AITechTrend. AITechTrend - Further into the Future. https://aitechtrend.com/how-cosine-similarity-can-improve-your-machine-learning-models/

Shah, S. R., Kaushik, A., Sharma, S., & Shah, J. (2020). Opinion-mining on marglish and devanagari comments of youtube cookery channels using parametric and non-parametric learning models. Big Data and Cognitive Computing, 4(1), 3.
"""